{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "title: Assignment 04\n",
        "author:\n",
        "  - name: Bhargavi Manyala\n",
        "    affiliations:\n",
        "      - id: bu\n",
        "        name: Boston University\n",
        "        city: Boston\n",
        "        state: MA\n",
        "number-sections: true\n",
        "date: today\n",
        "date-modified: today\n",
        "date-format: long\n",
        "format:\n",
        "  html:\n",
        "    theme: cerulean\n",
        "    toc: true\n",
        "    toc-depth: 2\n",
        "engine: jupyter\n",
        "jupyter: assignment-04-kernel\n",
        "execute:\n",
        "  echo: true\n",
        "  eval: true\n",
        "  output: true\n",
        "  freeze: auto\n",
        "---\n",
        "\n",
        "# Load the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/ubuntu/assignment-04-BhargaviManyala/.venv/lib/python3.12/site-packages/kaleido/__init__.py:14: UserWarning:\n",
            "\n",
            "\n",
            "\n",
            "Warning: You have Plotly version 6.0.0, which is not compatible with this version of Kaleido (1.0.0).\n",
            "\n",
            "This means that static image generation (e.g. `fig.write_image()`) will not work.\n",
            "\n",
            "Please upgrade Plotly to version 6.1.1 or greater, or downgrade Kaleido to version 0.2.1.\n",
            "\n",
            "\n",
            "Setting default log level to \"WARN\".\n",
            "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
            "25/09/29 19:47:38 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
            "25/09/29 19:47:58 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "import plotly.io as pio\n",
        "import numpy as np\n",
        "from pyspark.sql.functions import col, pow\n",
        "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.sql.functions import col, regexp_replace, trim\n",
        "\n",
        "\n",
        "np.random.seed(42)\n",
        "\n",
        "pio.renderers.default = \"notebook+notebook_connected+vscode\"\n",
        "\n",
        "# Initialize Spark Session\n",
        "spark = SparkSession.builder.appName(\"LightcastData\").getOrCreate()\n",
        "\n",
        "# Load Data\n",
        "df = (\n",
        "    spark.read\n",
        "    .option(\"header\", \"true\")\n",
        "    .option(\"inferSchema\", \"true\")\n",
        "    .option(\"multiLine\", \"true\")\n",
        "    .option(\"escape\", \"\\\"\")  \n",
        "    .csv(\"data/lightcast_job_postings.csv\")\n",
        "\n",
        ")\n",
        "\n",
        "df.createOrReplaceTempView(\"job_postings\")\n",
        "#df.show(5)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Feature Engineering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Selection of Variables and Dropping NA's\n",
        "* I referred to Claude to decide which cast (Float, Double, or Integer) should be used for numeric columns."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Data cleaned and numeric columns casted \n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Variable Selection\n",
        "min_years = \"MIN_YEARS_EXPERIENCE\"\n",
        "cont_cols = [\"MAX_YEARS_EXPERIENCE\", \"DURATION\", \"SALARY_FROM\"]\n",
        "cat_cols = [\"EMPLOYMENT_TYPE_NAME\", \"EDUCATION_LEVELS_NAME\"]\n",
        "y_col = \"SALARY\"\n",
        "\n",
        "# Dropping NA's\n",
        "required_cols = [min_years] + cont_cols + cat_cols + [y_col]\n",
        "df_clean = df.dropna(subset=required_cols)\n",
        "\n",
        "# Clean EDUCATION_LEVELS_NAME\n",
        "df_clean = df_clean.withColumn(\n",
        "    \"EDUCATION_LEVELS_NAME\",\n",
        "    trim(regexp_replace(col(\"EDUCATION_LEVELS_NAME\"), r\"[\\[\\]\\n\\\"]\", \"\"))\n",
        ")\n",
        "\n",
        " #  Cast numeric columns to double \n",
        "for c in [y_col, min_years] + cont_cols:\n",
        "    df_clean = df_clean.withColumn(c, col(c).cast(\"double\"))\n",
        "\n",
        "# Data Cleaned\n",
        "print(\" Data cleaned and numeric columns casted \")\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
